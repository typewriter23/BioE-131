{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\t\n",
    "\n",
    "You’re\tworking\tat\ta\tbiotech\tcompany\tthat\tgenerates\t1000\tterabytes\tof\tdata\tevery\tday.\tIn\ta\tmeeting,\tyour\tboss\tmentions\tthat\tit\tcosts\tthe\tcompany\t$50\tper\tterabyte\tof\thard\tdisk\tspace,\tand\tso\tevery\t1%\treduction\tin\tdata\tthat\tmust\tbe\tstored\ttranslates\tinto\ta\t$500\tsavings\tper\tday.\tYour\tteam\twill\tget\ta\tbonus\tthis\tyear\tequal\tto\tthe\tamount\tof\tsavings\tyou’re\table\tto\tgenerate\tby\tcompressing\tthe\tcompany’s\tdata.\t\n",
    "\n",
    "Incentivized\tby\tthis\tbonus,\tyour\tteam\tgets\tto\twork\tdetermining\twhich\tcompression\talgorithm\twill\tgenerate\tthe\tmost\tsavings.\tThe\talgorithm\tyou\tchoose\tmust\teither\tbe\tquick\tenough\tto\tcompress\t1000\tterabytes\ta\tday,\tor\tefficient\tenough\tthat\teven\tif\tall\tthe\tdata\tisn’t\tcompressed,\tthe\tsavings\tare\tmaximized\tby\tthe\tdata\tthat\tyou\thave\ttime\tto\tcompress.\t\n",
    "\n",
    "# Simulating\tthe\tdata\t\n",
    "\n",
    "Fortunately,\tyou\tknow\tthat\tmost\tof\tthe\tdata\tyou’ll\tbe\tcompressing\twill\tbe\tnucleic\tacid\tsequences.\tSome\tof\tit,\thowever,\twill\tbe\tbinary\tfiles,\tand\tsome\twill\tbe\tprotein\tsequences.\tStart\tby\twriting\tsome\tcode\tto\tsimulate\tfiles\tcontaining\trandom\tDNA,\tprotein,\tand\tbinary\tdata.\tUsing\tnp.random.choice,\tgenerate\t100\tmegabytes\t(8\tbits/byte\t*\t1e6 bytes/megabyte)\tof\trandom\tdata\tcontaining\t100%,\t90%,\t80%,\t70%,\t60%,\tand\t50%\tzeros.\tBe\tsure\tto\tcall\tnp.packbits\ton\tyour\tdata\tbefore\twriting\tit\tto\ta\tfile.\tFor\texample:\tmyvar = np.random.choice([0, 1], size=1024, replace=True, p=[0.5, 0.5]) myvar = np.packbits(myvar) Then\twrite\tthis\tdata\tto\ta\tfile\tin\tyour\thome\tdirectory,\tlike\tthis:\topen(“zeros_100p”, “wb”).write(zeros_100p) Next,\tgenerate\tone DNA\tand\tone protein\tsequence, each\t100\tmillion\tletters\tlong,\tand\twrite\tthose\tto\tyour\thome\tdirectory.\tThe\tprobability\tof\teach\tletter\tshould\tbe\tequal.\tTo\twrite\tstrings\tgenerated\tin\tNumpy\tto\ta\tfile,\tyou’ll\thave\tto\tuse\ta\tslightly\tdifferent\tcommand,\tlike\tthis:\topen(“nt_seq.fa”, “w”).write(“”.join(my_nt_seq)) Compressing\tthe\tdata\tYou’ll\thave\tto\tdo\tthis\tfrom\tthe\tterminal. Make sure to show the commands that you use in markdown.\tOn\teach\tof\tthe\tfiles\tyou\tgenerated\tabove,\trun\tgzip,\tbzip,\tand pbzip2\tas\tfollows:\t\n",
    "time gzip –c zeros_100p > zeros_100p.gz time bzip2 –k zeros_100p time pbzip2 –k zeros_100p  The\ttime\tcommand\ton\tLinux\twill\trun\twhatever\tcommands\tfollow\tand\treport\thow\tlong\tit\ttook.\tGzip\tand\tBzip2\twill\tsilently\tcompress\tyour\tfile\tand\tproduce\ta\tnew\tfile\twith\tthe\textension\t.gz\tor\t\n",
    ".bz2,\trespectively.\tThe\t–k\t(or -c) option\ttells\tthem\tnot\tto\tdelete\tthe\toriginal\tfile\tonce\tthe\tcompression\thas\tcompleted.\tgzip takes\tthe\tinput\tfile\tas\tthe\tfirst\tparameter\tand\tthe\toutput\tfile\tas\tthe\tsecond\tparameter.\t\n",
    "\n",
    "Keep\ttrack\tof\tthe\tsize\tof\tthe\tinput\tfiles,\tthe\tsize\tof\tthe\toutput\tfiles,\tand\tthe\ttime\teach\tcommand\ttook\tto\trun\tin\ta\ttable\tin\tyour\tiPython\tnotebook.\t\n",
    "Questions\tPlease\tanswer\tthese\tin\tyour\tiPython\tnotebook.\t\n",
    "Which\talgorithm\tachieves\tthe\tbest\tlevel\tof\tcompression\ton\teach\tfile\ttype?\tWhich\talgorithm\tis\tthe\tfastest?\tWhat\tis\tthe\tdifference\tbetween\tbzip2\tand\tpbzip2?\tDo\tyou\texpect\tone\tto\tbe\tfaster\tand\twhy?\t\n",
    "How\tdoes\tthe\tlevel\tof\tcompression\tchange\tas\tthe\tpercentage\tof\tzeros\tincreases?\tWhy\tdoes\tthis\thappen?\t\n",
    "What\tis\tthe\tminimum\tnumber\tof\tbits\trequired\tto\tstore\ta\tsingle\tDNA\tbase?\tWhat\tis\tthe\tminimum\tnumber\tof\tbits\trequired\tto\tstore\tan\tamino\tacid\tletter?\tIn\tyour\ttests,\thow\tmany\tbits\tdid\tgzip\tand\tbzip2\tactually\trequire\tto\tstore\tyour\trandom\tDNA\tand\tprotein\tsequences?\tAre\tgzip\tand\tbzip2\tperforming\twell\ton\tDNA\tand\tproteins?\t\n",
    "Compressing\treal\tdata\tNow\tthat\tyou\thave\ta\tsense\tof\thow\trandom\tdata\tcan\tbe\tcompressed,\tlet’s\thave\ta\tlook\tat\tsome\treal\tbiological\tdata.\tUsing\twhat\tyou’ve\tlearned\tabout\tquerying\tbiological\tdatabases,\tfind\tthe\tnucleic\tacid\tsequences\tof\tgp120\thomologs\tfrom\tat\tleast\t10\tdifferent\tHIV\tisolates\tand\tconcatenate\tthem\ttogether\tinto\ta\tsingle\tmulti-FASTA.\t\n",
    "A\tpriori,\tdo\tyou\texpect\tto\tachieve\tbetter\tor\tworse\tcompression\there\tthan\trandom\tdata?\tWhy?\t\n",
    "Now,\tcompress\tthe\tmulti-FASTA\tusing\tgzip and bzip2.\t\n",
    "How\tdoes\tthe\tcompression\tratio\tof\tthis\tfile\tcompare\tto\trandom\tdata?\t\n",
    "Estimating\tcompression\tof\t1000\tterabytes\tLet’s\tmake\tsome\tassumptions\tabout\tthe\tcontents\tof\tthe\tdata\tat\tyour\tbiotech\tcompany.\tMost\tof\tthe\tdata,\tsay\t80%,\tis\tre-sequencing\tof\tgenomes\tand\tplasmids\tthat\tare\tvery\tsimilar\tto\teach\tother.\tAnother\t10%\tmight\tbe\tprotein\tsequences,\tand\tthe\tlast\t10%\tare\tbinary\tmicroscope\timages\twhich\twe’ll\tassume\tfollow\tthe\tworst-case\tscenario\tof\tbeing\tcompletely\trandom.\t\n",
    "Given\tthe\tbenchmarking\tdata\tyou\tobtained\tin\tthis\tlab,\twhich\talgorithm\tdo\tyou\tpropose\tto\tuse\tfor\teach\ttype\tof\tdata?\tProvide\tan\testimate\tfor\tthe\tfraction\tof\tspace\tyou\tcan\tsave\tusing\tyour\tcompression\tscheme.\tHow\tmuch\tof\ta\tbonus\tdo\tyou\tanticipate\treceiving\tthis\tyear?\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!\n",
    "\n",
    "\n",
    "Fortunately,\tyou\tknow\tthat\tmost\tof\tthe\tdata\tyou’ll\tbe\tcompressing\twill\tbe\tnucleic\tacid\tsequences.\tSome\tof\tit,\thowever,\twill\tbe\tbinary\tfiles,\tand\tsome\twill\tbe\tprotein\tsequences.\tStart\tby\twriting\tsome\tcode\tto\tsimulate\tfiles\tcontaining\trandom\tDNA,\tprotein,\tand\tbinary\tdata.\t\n",
    "\n",
    "\n",
    "Using\tnp.random.choice,\tgenerate\t100\tmegabytes\t(8\tbits/byte\t*\t1e6 bytes/megabyte)\tof\trandom\tdata\tcontaining\t100%,\t90%,\t80%,\t70%,\t60%,\tand\t50%\tzeros.\t\n",
    "\n",
    "\n",
    "Be\tsure\tto\tcall\tnp.packbits\ton\tyour\tdata\tbefore\twriting\tit\tto\ta\tfile.\tFor\texample:\tmyvar = np.random.choice([0, 1], size=1024, replace=True, p=[0.5, 0.5]) myvar = np.packbits(myvar) Then\twrite\tthis\tdata\tto\ta\tfile\tin\tyour\thome\tdirectory,\tlike\tthis:\topen(“zeros_100p”, “wb”).write(zeros_100p) Next,\tgenerate\tone DNA\tand\tone protein\tsequence, each\t100\tmillion\tletters\tlong,\tand\twrite\tthose\tto\tyour\thome\tdirectory.\tThe\tprobability\tof\teach\tletter\tshould\tbe\tequal.\tTo\twrite\tstrings\tgenerated\tin\tNumpy\tto\ta\tfile,\tyou’ll\thave\tto\tuse\ta\tslightly\tdifferent\tcommand,\tlike\tthis:\topen(“nt_seq.fa”, “w”).write(“”.join(my_nt_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Bio.Seq import Seq\n",
    "from Bio import Alphabet\n",
    "from Bio.Alphabet import Reduced\n",
    "import subprocess\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First want to simulate the data:\n",
    "\n",
    "# Let there be an equal number of all 6 %'s\n",
    "\n",
    "\n",
    "def genZeroData(dataSize, p_0): # I only need to know how big and the percentage\n",
    "    myvar = np.random.choice([0, 1], size=dataSize, replace=True, p=[p_0, 1-p_0]) \n",
    "    myvar = np.packbits(myvar) \n",
    "    filename = \"./Data/zeros_{0}\".format(p_0)\n",
    "    with open(filename, \"wb\") as file:\n",
    "        file.write(myvar)\n",
    "genZeroData(100, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_vals = [1.0, 0.9, 0.8, 0.7, 0.6, 0.5]\n",
    "size = 10**6\n",
    "for p in prob_vals:\n",
    "    genZeroData(size, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulating Protein Data:\n",
    "prot_size = 100000000\n",
    "prot_alphabet = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "prot = np.random.choice(prot_alphabet, size=prot_size, replace=True) \n",
    "# print(list(prot))\n",
    "\n",
    "open(\"./Data/2019_10_23_prot_seq.fa\", \"w\").write(\"\".join(prot)) \n",
    "\n",
    "# def genAlphabetData(dataSize, p_alphabet = None, alphabet): # I only need to know how big and the percentage\n",
    "#     myvar = np.random.choice([0, 1], size=dataSize, replace=True, p=[p_0, 1-p_0]) \n",
    "#     myvar = np.packbits(myvar) \n",
    "#     filename = \"zeros_{0}\".format(p_0)\n",
    "#     with open(filename, \"wb\") as file:\n",
    "#         file.write(myvar)\n",
    "# genAlphabetData(100, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulating Nucleotide Data:\n",
    "nt_size = 100000000\n",
    "nt_alphabet = [\"A\", \"T\", \"G\", \"C\"]\n",
    "nt = np.random.choice(prot_alphabet, size=prot_size, replace=True) \n",
    "# print(list(prot))\n",
    "\n",
    "open(\"./Data/2019_10_23_nt_seq.fa\", \"w\").write(\"\".join(prot)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 'gzip -c zeros_0.9 > zeros_100p.gz' > temp.txt 2>logs/2019_10_23_gzip_zeros_0.9_log.txt\n",
      "time 'gzip -c 2019_10_23_prot_seq.fa > zeros_100p.gz' > temp.txt 2>logs/2019_10_23_gzip_2019_10_23_prot_seq.fa_log.txt\n",
      "time 'gzip -c zeros_0.7 > zeros_100p.gz' > temp.txt 2>logs/2019_10_23_gzip_zeros_0.7_log.txt\n",
      "time 'gzip -c zeros_0.9.bz2 > zeros_100p.gz' > temp.txt 2>logs/2019_10_23_gzip_zeros_0.9.bz2_log.txt\n",
      "time 'gzip -c zeros_06 > zeros_100p.gz' > temp.txt 2>logs/2019_10_23_gzip_zeros_06_log.txt\n",
      "time 'gzip -c zeros_0.8.bz2 > zeros_100p.gz' > temp.txt 2>logs/2019_10_23_gzip_zeros_0.8.bz2_log.txt\n",
      "time 'gzip -c zeros_0.6 > zeros_100p.gz' > temp.txt 2>logs/2019_10_23_gzip_zeros_0.6_log.txt\n",
      "time 'gzip -c zeros_1.0 > zeros_100p.gz' > temp.txt 2>logs/2019_10_23_gzip_zeros_1.0_log.txt\n",
      "time 'gzip -c zeros_0.5 > zeros_100p.gz' > temp.txt 2>logs/2019_10_23_gzip_zeros_0.5_log.txt\n",
      "time 'gzip -c zeros_0.7.bz2 > zeros_100p.gz' > temp.txt 2>logs/2019_10_23_gzip_zeros_0.7.bz2_log.txt\n",
      "time 'gzip -c zeros_0.6.bz2 > zeros_100p.gz' > temp.txt 2>logs/2019_10_23_gzip_zeros_0.6.bz2_log.txt\n",
      "time 'gzip -c 2019_10_23_nt_seq.fa > zeros_100p.gz' > temp.txt 2>logs/2019_10_23_gzip_2019_10_23_nt_seq.fa_log.txt\n"
     ]
    }
   ],
   "source": [
    "# Running the commands on the terminal from Jup Notebook because nobody tells Jerry what to do\n",
    "\n",
    "# First, find all files you want to zip:\n",
    "# Stolen from: https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "data_files = [f for f in listdir(\"./Data\") if isfile(join(\"./Data\", f))] \n",
    "\n",
    "gzip_stem = \"time 'gzip -c {dataname} > zeros_100p.gz' > temp.txt 2>logs/2019_10_23_gzip_{dataname}_log.txt\"\n",
    "bzip2_stem = \"time 'bzip2 -k {dataname}' > temp.txt 2>logs/2019_10_23_bzip2_{dataname}_log.txt\"\n",
    "pbzip2_stem = \"time 'pbzip2 -k {dataname}' > temp.txt 2>'logs/2019_10_23_pbzip2_{dataname}_log.txt'\"\n",
    "\n",
    "\n",
    "def zip_all(origin_file):\n",
    "    origin_file = origin_file # os.path.join(\"./Data\", origin_file)\n",
    "    gzip_comm = gzip_stem.format(dataname = origin_file)\n",
    "    bzip2_comm = bzip2_stem.format(dataname = origin_file)\n",
    "    pbzip2_comm = pbzip2_stem.format(dataname = origin_file)\n",
    "    \n",
    "    print(gzip_comm)\n",
    "    \n",
    "    os.system(gzip_comm)\n",
    "    os.system(bzip2_comm)\n",
    "    os.system(pbzip2_comm)\n",
    "for f in data_files:\n",
    "    zip_all(f)\n",
    "# !time gzip –c zeros_100p > zeros_100p.gz > \"2019_10_23_{dataname}_log.txt\"\n",
    "# !time bzip2 –k zeros_100p \n",
    "# !time pbzip2 –k zeros_100p\n",
    "\n",
    "# data_files\n",
    "\n",
    "# Fuck this shit I'll just use bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: -c: line 1: syntax error: unexpected end of file\n",
      "/usr/bin/sh: -c: line 0: syntax error near unexpected token `do'\n",
      "/usr/bin/sh: -c: line 0: `do'\n",
      "/usr/bin/sh: cmd: command not found\n",
      "/usr/bin/sh: -c: line 0: syntax error near unexpected token `done'\n",
      "/usr/bin/sh: -c: line 0: `done'\n"
     ]
    }
   ],
   "source": [
    "# !for file in /dir/*\n",
    "# !do\n",
    "# !  cmd [option] \"$file\" >> results.out\n",
    "# !done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo time gzip -c ./Data/zeros_0.9 > ./Data/zeros_0.9.gz;time gzip -c ./Data/zeros_0.9 > ./Data/zeros_0.9.gz;echo time bzip2 -k ./Data/zeros_0.9;time bzip2 -k ./Data/zeros_0.9;echo time pbzip2 -k ./Data/zeros_0.9 -f;time pbzip2 -k ./Data/zeros_0.9 -f;echo time gzip -c ./Data/2019_10_23_prot_seq.fa > ./Data/2019_10_23_prot_seq.fa.gz;time gzip -c ./Data/2019_10_23_prot_seq.fa > ./Data/2019_10_23_prot_seq.fa.gz;echo time bzip2 -k ./Data/2019_10_23_prot_seq.fa;time bzip2 -k ./Data/2019_10_23_prot_seq.fa;echo time pbzip2 -k ./Data/2019_10_23_prot_seq.fa -f;time pbzip2 -k ./Data/2019_10_23_prot_seq.fa -f;echo time gzip -c ./Data/zeros_0.7 > ./Data/zeros_0.7.gz;time gzip -c ./Data/zeros_0.7 > ./Data/zeros_0.7.gz;echo time bzip2 -k ./Data/zeros_0.7;time bzip2 -k ./Data/zeros_0.7;echo time pbzip2 -k ./Data/zeros_0.7 -f;time pbzip2 -k ./Data/zeros_0.7 -f;echo time gzip -c ./Data/zeros_06 > ./Data/zeros_06.gz;time gzip -c ./Data/zeros_06 > ./Data/zeros_06.gz;echo time bzip2 -k ./Data/zeros_06;time bzip2 -k ./Data/zeros_06;echo time pbzip2 -k ./Data/zeros_06 -f;time pbzip2 -k ./Data/zeros_06 -f;echo time gzip -c ./Data/zeros_0.6 > ./Data/zeros_0.6.gz;time gzip -c ./Data/zeros_0.6 > ./Data/zeros_0.6.gz;echo time bzip2 -k ./Data/zeros_0.6;time bzip2 -k ./Data/zeros_0.6;echo time pbzip2 -k ./Data/zeros_0.6 -f;time pbzip2 -k ./Data/zeros_0.6 -f;echo time gzip -c ./Data/zeros_1.0 > ./Data/zeros_1.0.gz;time gzip -c ./Data/zeros_1.0 > ./Data/zeros_1.0.gz;echo time bzip2 -k ./Data/zeros_1.0;time bzip2 -k ./Data/zeros_1.0;echo time pbzip2 -k ./Data/zeros_1.0 -f;time pbzip2 -k ./Data/zeros_1.0 -f;echo time gzip -c ./Data/zeros_0.5 > ./Data/zeros_0.5.gz;time gzip -c ./Data/zeros_0.5 > ./Data/zeros_0.5.gz;echo time bzip2 -k ./Data/zeros_0.5;time bzip2 -k ./Data/zeros_0.5;echo time pbzip2 -k ./Data/zeros_0.5 -f;time pbzip2 -k ./Data/zeros_0.5 -f;echo time gzip -c ./Data/2019_10_23_nt_seq.fa > ./Data/2019_10_23_nt_seq.fa.gz;time gzip -c ./Data/2019_10_23_nt_seq.fa > ./Data/2019_10_23_nt_seq.fa.gz;echo time bzip2 -k ./Data/2019_10_23_nt_seq.fa;time bzip2 -k ./Data/2019_10_23_nt_seq.fa;echo time pbzip2 -k ./Data/2019_10_23_nt_seq.fa -f;time pbzip2 -k ./Data/2019_10_23_nt_seq.fa -f;"
     ]
    }
   ],
   "source": [
    "# Want to systematically generate all bash commands:\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "data_files = [f for f in listdir(\"./Data\") if isfile(join(\"./Data\", f))] \n",
    "\n",
    "gzip_stem = \"time gzip -c {dataname} > {dataname}.gz\"\n",
    "bzip2_stem = \"time bzip2 -k {dataname}\"\n",
    "pbzip2_stem = \"time pbzip2 -k {dataname} -f\"\n",
    "\n",
    "\n",
    "def zip_all(origin_file):\n",
    "    origin_file = os.path.join(\"./Data\", origin_file) # origin_file # os.path.join(\"./Data\", origin_file)\n",
    "    gzip_comm = gzip_stem.format(dataname = origin_file)\n",
    "    bzip2_comm = bzip2_stem.format(dataname = origin_file)\n",
    "    pbzip2_comm = pbzip2_stem.format(dataname = origin_file)\n",
    "    \n",
    "    # print(gzip_comm)\n",
    "    print(\"echo {}\".format(gzip_comm), end =\";\")\n",
    "    print(gzip_comm, end =\";\")\n",
    "    print(\"echo \" + bzip2_comm, end =\";\")\n",
    "    print(bzip2_comm, end =\";\")\n",
    "    print(\"echo \" + pbzip2_comm, end =\";\")\n",
    "    print(pbzip2_comm, end =\";\")\n",
    "for f in data_files:\n",
    "    zip_all(f)\n",
    "# !time gzip –c zeros_100p > zeros_100p.gz > \"2019_10_23_{dataname}_log.txt\"\n",
    "# !time bzip2 –k zeros_100p \n",
    "# !time pbzip2 –k zeros_100p"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Timing Results:\n",
    "\n",
    "time gzip -c ./Data/zeros_0.9 > ./Data/zeros_0.9.gz\n",
    "real    0m0.031s\n",
    "user    0m0.028s\n",
    "sys     0m0.004s\n",
    "time bzip2 -k ./Data/zeros_0.9\n",
    "\n",
    "real    0m0.013s\n",
    "user    0m0.013s\n",
    "sys     0m0.000s\n",
    "time pbzip2 -k ./Data/zeros_0.9 -f\n",
    "\n",
    "real    0m0.014s\n",
    "user    0m0.014s\n",
    "sys     0m0.000s\n",
    "time gzip -c ./Data/z2019_10_23_prot_seq.fa\n",
    "real    0m4.341s\n",
    "user    0m4.174s\n",
    "sys     0m0.068s\n",
    "time bzip2 -k ./Data/2019_10_23_prot_seq.fa\n",
    "\n",
    "real    0m9.358s\n",
    "user    0m9.281s\n",
    "sys     0m0.076s\n",
    "time pbzip2 -k ./Data/2019_10_23_prot_seq.fa -f\n",
    "\n",
    "real    0m1.093s\n",
    "user    0m14.454s\n",
    "sys     0m0.571s\n",
    "\n",
    "real    0m0.009s\n",
    "user    0m0.009s\n",
    "sys     0m0.000s\n",
    "time bzip2 -k ./Data/zeros_0.7\n",
    "\n",
    "real    0m0.014s\n",
    "user    0m0.014s\n",
    "sys     0m0.000s\n",
    "time pbzip2 -k ./Data/zeros_0.7 -f\n",
    "\n",
    "real    0m0.017s\n",
    "user    0m0.016s\n",
    "sys     0m0.000s\n",
    "\n",
    "real    0m0.006s\n",
    "user    0m0.006s\n",
    "sys     0m0.000s\n",
    "time bzip2 -k ./Data/zeros_06\n",
    "\n",
    "real    0m0.016s\n",
    "user    0m0.015s\n",
    "sys     0m0.000s\n",
    "time pbzip2 -k ./Data/zeros_06 -f\n",
    "\n",
    "real    0m0.019s\n",
    "user    0m0.015s\n",
    "sys     0m0.004s\n",
    "\n",
    "real    0m0.006s\n",
    "user    0m0.006s\n",
    "sys     0m0.000s\n",
    "time bzip2 -k ./Data/zeros_0.6\n",
    "\n",
    "real    0m0.015s\n",
    "user    0m0.015s\n",
    "sys     0m0.000s\n",
    "time pbzip2 -k ./Data/zeros_0.6 -f\n",
    "\n",
    "real    0m0.019s\n",
    "user    0m0.015s\n",
    "sys     0m0.004s\n",
    "\n",
    "time gzip -c ./Data/zeros_1.0 > ./Data/zeros_1.0.gz\n",
    "real    0m0.002s\n",
    "user    0m0.001s\n",
    "sys     0m0.000s\n",
    "time bzip2 -k ./Data/zeros_1.0\n",
    "\n",
    "real    0m0.002s\n",
    "user    0m0.002s\n",
    "sys     0m0.000s\n",
    "time pbzip2 -k ./Data/zeros_1.0 -f\n",
    "\n",
    "real    0m0.003s\n",
    "user    0m0.003s\n",
    "sys     0m0.000s\n",
    "\n",
    "real    0m0.005s\n",
    "user    0m0.005s\n",
    "sys     0m0.000s\n",
    "time bzip2 -k ./Data/zeros_0.5\n",
    "\n",
    "real    0m0.016s\n",
    "user    0m0.016s\n",
    "sys     0m0.000s\n",
    "time pbzip2 -k ./Data/zeros_0.5 -f\n",
    "\n",
    "real    0m0.020s\n",
    "user    0m0.020s\n",
    "sys     0m0.000s\n",
    "\n",
    "real    0m4.335s\n",
    "user    0m4.211s\n",
    "sys     0m0.036s\n",
    "time bzip2 -k ./Data/2019_10_23_nt_seq.fa\n",
    "\n",
    "real    0m9.353s\n",
    "user    0m9.313s\n",
    "sys     0m0.040s\n",
    "time pbzip2 -k ./Data/2019_10_23_nt_seq.fa -f\n",
    "\n",
    "real    0m1.083s\n",
    "user    0m14.427s\n",
    "sys     0m0.548s"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Storage Results:\n",
    "-rw-rw-r-- 1 5447414 5447414  69K Oct 24 09:49 zeros_0.9.gz\n",
    "-rw-rw-r-- 1 5447414 5447414  58M Oct 24 09:49 2019_10_23_prot_seq.fa.gz\n",
    "-rw-rw-r-- 1 5447414 5447414 110K Oct 24 09:50 zeros_0.7.gz\n",
    "-rw-rw-r-- 1 5447414 5447414 120K Oct 24 09:50 zeros_06.gz\n",
    "-rw-rw-r-- 1 5447414 5447414 120K Oct 24 09:50 zeros_0.6.gz\n",
    "-rw-rw-r-- 1 5447414 5447414  166 Oct 24 09:50 zeros_1.0.gz\n",
    "-rw-rw-r-- 1 5447414 5447414 123K Oct 24 09:50 zeros_0.5.gz\n",
    "-rw-rw-r-- 1 5447414 5447414  58M Oct 24 09:50 2019_10_23_nt_seq.fa.gz\n",
    "\n",
    "-rw-rw-r-- 1 5447414 5447414  53M Oct 24 06:41 2019_10_23_prot_seq.fa.bz2\n",
    "-rw-rw-r-- 1 5447414 5447414  53M Oct 24 06:41 2019_10_23_nt_seq.fa.bz2\n",
    "-rw-rw-r-- 1 5447414 5447414 123K Oct 24 08:56 zeros_06.bz2\n",
    "-rw-rw-r-- 1 5447414 5447414   47 Oct 24 09:32 zeros_1.0.bz2\n",
    "-rw-rw-r-- 1 5447414 5447414  72K Oct 24 09:32 zeros_0.9.bz2\n",
    "-rw-rw-r-- 1 5447414 5447414 117K Oct 24 09:32 zeros_0.7.bz2\n",
    "-rw-rw-r-- 1 5447414 5447414 123K Oct 24 09:32 zeros_0.6.bz2\n",
    "-rw-rw-r-- 1 5447414 5447414 124K Oct 24 09:32 zeros_0.5.bz2\n",
    "\n",
    "-rw-rw-r-- 1 5447414 5447414  96M Oct 24 06:41 2019_10_23_prot_seq.fa\n",
    "-rw-rw-r-- 1 5447414 5447414  96M Oct 24 06:41 2019_10_23_nt_seq.f\n",
    "-rw-rw-r-- 1 5447414 5447414 123K Oct 24 09:32 zeros_1.0\n",
    "-rw-rw-r-- 1 5447414 5447414 123K Oct 24 09:32 zeros_0.9\n",
    "-rw-rw-r-- 1 5447414 5447414 123K Oct 24 09:32 zeros_0.7\n",
    "-rw-rw-r-- 1 5447414 5447414 123K Oct 24 09:32 zeros_0.6\n",
    "-rw-rw-r-- 1 5447414 5447414 123K Oct 24 09:32 zeros_0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressing data: Results:\n",
    "\n",
    "| Datafile  | Input Size  |  Output Size (gz) | Output Size (bz2)| Time to Compress |\n",
    "|---|---|---| | |\n",
    "| zeros_1.0  | 123K  |  166 |47 |0m0.002s | \n",
    "|  zeros_0.9 |  123K | 69K  |72K | 0m0.031s | \n",
    "| zeros_0.7  | 123K  | 110K  |117K |0m4.341s |\n",
    "|  zeros_0.6 | 123K  | 120K  | 123K  | 0m0.015s  |\n",
    "| zeros_0.5  |  123K |   123K | 124K  | 0m0.005s  |\n",
    "| 2019_10_23_prot_seq.fa  |  96M |  58M  | 53M  | 0m4.341s  |\n",
    "| 019_10_23_nt_seq.fa  | 96M  |  58M  |  53M |  0m4.335s  |\n",
    "|   |   |   |   |   |\n",
    "|   |   |   |   |   |\n",
    "|   |   |   |   |   |\n",
    "|   |   |   |   |   |\n",
    "|   |   |   |   |   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which\talgorithm\tachieves\tthe\tbest\tlevel\tof\tcompression\ton\teach\tfile\ttype?\t\n",
    "- FASTA Nucleotide: bzip2's algorithm gives the best level of compression: 96 MB > 53 MB vs 56 MB\n",
    "- FASTA Protein: bzip2 also, with the same numbers\n",
    "- All zero files: gzip was better\n",
    "\n",
    "# Which\talgorithm\tis\tthe\tfastest?\t\n",
    "- From the data collected here, pbzip2\n",
    "\n",
    "# What\tis\tthe\tdifference\tbetween\tbzip2\tand\tpbzip2?\t\n",
    "From: https://linux.die.net/man/1/pbzip2\n",
    "\n",
    "\"pbzip2 is a parallel implementation of the bzip2 block-sorting file compressor that uses pthreads and achieves near-linear speedup on SMP machines\"\n",
    "\n",
    "\n",
    "# Do\tyou\texpect\tone\tto\tbe\tfaster\tand\twhy?\t\n",
    "\n",
    "Since pbzip2 is parallelized, it shouldbe faster than the non=parallelized bzip.\n",
    "\n",
    "# How\tdoes\tthe\tlevel\tof\tcompression\tchange\tas\tthe\tpercentage\tof\tzeros\tincreases?\t\n",
    "If follows the following trend: the amount of memory required is maximum at 0.5, and decreases steadily towards 1.0\n",
    "\n",
    "# Why\tdoes\tthis\thappen?\t\n",
    "\n",
    "It is because the bits required to encode a random number of 1's and 0's is maximized with a uniform distribution. The more one deviated from a unifrom distribution, the fewer bits one needs.\n",
    "\n",
    "# What\tis\tthe\tminimum\tnumber\tof\tbits\trequired\tto\tstore\ta\tsingle\tDNA\tbase?\t\n",
    "Since there exist 4 options, we need log_2(4) = 2 bits\n",
    "\n",
    "# What\tis\tthe\tminimum\tnumber\tof\tbits\trequired\tto\tstore\tan\tamino\tacid\tletter?\t\n",
    "Since there exist 20 options, we need log_2(20) (rounded up) = 5 bits\n",
    "\n",
    "# In\tyour\ttests,\thow\tmany\tbits\tdid\tgzip\tand\tbzip2\tactually\trequire\tto\tstore\tyour\trandom\tDNA\tand\tprotein\tsequences?\t\n",
    "gzip: 53 MB\n",
    "bzip2: 58 MB\n",
    "\n",
    "# Are\tgzip\tand\tbzip2\tperforming\twell\ton\tDNA\tand\tproteins?\t\n",
    "They are able to compress the files, but not as well as would be with an ideal code. So well, but not ideal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with real data:\n",
    "## A\tpriori,\tdo\tyou\texpect\tto\tachieve\tbetter\tor\tworse\tcompression\there\tthan\trandom\tdata?\tWhy?\t\n",
    "Since randomly and iid sequences have the maximum entropy, and the real data must be at least as good or better than the random data. Since there should be some sequence similarity and patterns within real data, there should be better compression.\n",
    "\n",
    "## Now,\tcompress\tthe\tmulti-FASTA\tusing\tgzip and bzip2.\t\n",
    "Multi-fasta located at ./Data/HIV_genes.fasta\n",
    "Compressed-fasta located at ./Data/HIV_genes.fasta.gz and .bz2\n",
    ".gz: 1.5 kb\n",
    ".bz2: 1.4 kb\n",
    "original: 4.2 kb\n",
    "## How\tdoes\tthe\tcompression\tratio\tof\tthis\tfile\tcompare\tto\trandom\tdata?\n",
    "It is much better. Using the randomly slected HIV genes, we have a compression ratio of around 0.3, whereas with random data, we saw a compression ratio closer to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compression of 1000 Terabytes\n",
    "\n",
    "- For the 10% binary microscope images: Very little compression. No money earned here\n",
    "- For the 90% sequences: Since there is a lot of redundancy, we can save here.\n",
    "\n",
    "\n",
    "\n",
    "# Given\tthe\tbenchmarking\tdata\tyou\tobtained\tin\tthis\tlab,\twhich\talgorithm\tdo\tyou\tpropose\tto\tuse\tfor\teach\ttype\tof\tdata?\tProvide\tan\testimate\tfor\tthe\tfraction\tof\tspace\tyou\tcan\tsave\tusing\tyour\tcompression\tscheme.\t\n",
    "since we are working with genomic data, the gzip algorithm performed better. We can save around 60-70% using this compression scheme, using the empirical data gathered here.\n",
    "\n",
    "# How\tmuch\tof\ta\tbonus\tdo\tyou\tanticipate\treceiving\tthis\tyear?\n",
    "On the order of $4500"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
